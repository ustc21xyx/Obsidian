## 实验简介
`Doc2Vec` 是一种无监督的算法，用于生成文档的向量表示。它是 `Word2Vec` 的扩展，可以捕捉到词语的语义信息，同时还能捕捉到文档级别的信息。`Doc2Vec` 有两种主要的实现方式：`PV-DM`（Paragraph Vector - Distributed Memory）和 `PV-DBOW`（Paragraph Vector - Distributed Bag of Words）。
这次实验使用Python的gensim库中的doc2vec接口完成

## 实验结果

|     | PV-DM  | PV-DBow |
| --- | ------ | ------- |
| HS  | 0.8272 | 0.8524  |
| NS  | 0.8588 | 0.8724  |

### 结果分析


一般情况，考虑了词序信息的PV-DM的准确度更高。但在这次实验中，**PV-DBOW的效果反而更好**，这可能是因为 PV-DBOW 模型在处理情感分析任务时，能够更好地捕捉到文档的全局信息，而不仅仅是局部的词序信息。
![|347](https://img-blog.csdn.net/20180130171730371?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSm9obl94eXo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
![|365](https://img-blog.csdn.net/20180130171804530?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSm9obl94eXo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
在这次实验中，NS的效果比HS更好，原因可能有以下几点：
1. 情感分析任务通常需要理解文本的全局语义信息，而 NS 在训练过程中，通过随机选择一部分负样本进行更新，更倾向于捕捉全局的语义信息。而 HS 则更注重精确地建模每个单词的上下文，可能更适合需要捕捉精细语义信息的任务。
2. NS 只需要更新一部分负样本的权重，而 HS 需要遍历哈夫曼树的所有路径，因此 NS 在计算效率上通常优于 HS。在大规模数据集上，NS 可能会在相同的训练时间内达到更好的优化效果。
3. NS 通过将多分类问题转化为二分类问题简化了模型，这可能使得模型更容易训练，从而得到更好的结果。

## 具体实现
### Doc2Vec模型初始化
首先，创建一个Doc2Vec模型的实例，并初始化它。这一步骤包括设置模型的各种参数，如向量大小（`vector_size`）、窗口大小（`window`）、最小词频（`min_count`）等。这些参数对模型的性能和结果有重要影响。
![](https://raw.githubusercontent.com/ustc21xyx/picture-bed/main/20240508133544.png)
各个参数含义如下：

| 参数          | 含义                           |
| ----------- | ---------------------------- |
| min_count   | 忽略所有总频率低于此值的词。               |
| window      | 当前词和预测词之间的最大距离。              |
| vector_size | 生成的特征向量的维度。                  |
| workers     | 练模型的工作线程数。                   |
| alpha       | 初始学习率。                       |
| min_alpha   | 随着训练的进行，学习率将线性下降到此值。         |
| dm          | dm=0时，为PV-DM；dm=1时，为PV-DBOW。 |
| hs          | hs=0时，为ns；hs=1时，为hs。         |
### 训练Doc2Vec模型

一旦模型初始化完成，下一步就是训练模型。训练过程中，我们会多次遍历整个语料库（epoch），每次遍历后都会随机打乱语料库的顺序，以提高模型的泛化能力。
![](https://raw.githubusercontent.com/ustc21xyx/picture-bed/main/20240508134144.png)

### 获取向量表示

训练完成后，我们可以从模型中提取文档向量。这些向量可以用于后续的机器学习任务，如分类、聚类等。![](https://raw.githubusercontent.com/ustc21xyx/picture-bed/main/20240508134241.png)
### 文档分类

在本例中，我们使用逻辑回归（Logistic Regression）作为分类器。首先，我们需要从Doc2Vec模型中获取训练和测试数据的向量表示，然后使用这些向量来训练分类器。