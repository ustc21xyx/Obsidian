## 实验简介
`Doc2Vec` 是一种无监督的算法，用于生成文档的向量表示。它是 `Word2Vec` 的扩展，可以捕捉到词语的语义信息，同时还能捕捉到文档级别的信息。`Doc2Vec` 有两种主要的实现方式：`PV-DM`（Paragraph Vector - Distributed Memory）和 `PV-DBOW`（Paragraph Vector - Distributed Bag of Words）。
这次实验使用Python的gensim库中的doc2vec接口完成

## 实验结果

|     | PV-DM  | PV-DBow |
| --- | ------ | ------- |
| HS  | 0.8272 | 0.8524  |
| NS  | 0.8588 | 0.8724  |

### 结果分析


一般情况，考虑了词序信息的PV-DM的准确度更高。但在这次实验中，**PV-DBOW的效果反而更好**，这可能是因为 PV-DBOW 模型在处理情感分析任务时，能够更好地捕捉到文档的全局信息，而不仅仅是局部的词序信息。
![|347](https://img-blog.csdn.net/20180130171730371?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSm9obl94eXo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
![|365](https://img-blog.csdn.net/20180130171804530?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSm9obl94eXo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
在这次实验中，NS的效果比HS更好，原因可能有以下几点：
1. 情感分析任务通常需要理解文本的全局语义信息，而 NS 在训练过程中，通过随机选择一部分负样本进行更新，更倾向于捕捉全局的语义信息。而 HS 则更注重精确地建模每个单词的上下文，可能更适合需要捕捉精细语义信息的任务。
2. NS 只需要更新一部分负样本的权重，而 HS 需要遍历哈夫曼树的所有路径，因此 NS 在计算效率上通常优于 HS。在大规模数据集上，NS 可能会在相同的训练时间内达到更好的优化效果。
3. NS 通过将多分类问题转化为二分类问题简化了模型，这可能使得模型更容易训练，从而得到更好的结果。

## 具体实现

首先，创建一个Doc2Vec模型的实例，并初始化它。这一步骤包括设置模型的各种参数，如向量大小（`vector_size`）、窗口大小（`window`）、最小词频（`min_count`）等。这些参数对模型的性能和结果有重要影响。
