注：本次实验使用 enwiki8 (http://mattmahoney.net/dc/enwik8.zip) 语料库，及https://github.com/deborausujono/word2vecpy的模型
## 性能结果
相似度计算使用余弦相似度

Spearman-correlation如下：

| 方法  | CBOW | SG   |
| --- | ---- | ---- |
| HS  | 0.24 | 0.57 |
| NS  | 0.23 | 0.36 |
其他超参数
• 向量维度:200
• 窗口大小:+/- 5词
• 词频过滤:5
- Number of negative examples:5
## 分析比较
在控制其他变量不变的情况下，SG得到的向量的相似度，比CBOW的向量更与标准数据相关，即**向量数据SG更好**，但相应的，**计算时间SG也比CBOW长**。
这可能是因为CBOW是通过上下文来预测一个词，这样学习的次数比较少，在遇到生僻词的时候效果比较差，而SG是通过一个词预测上下文，学习的次数比较多，可以更好的处理生僻词

在控制其他变量不变的情况下，HS比NS更好，但在CBOW时无明显优势。
HS使用了一个二叉树（通常是霍夫曼树）来计算词的概率，而NS通过随机抽取负样本来近似整个词汇表的概率分布。HS通常在处理大词汇表时更有效，而NS在小词汇表或者高质量负样本的情况下表现更好，而在处理CBOW时无明显优势。

### 实验过程






